{
 "cells": [
  {
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "This notebook is adapted from Microsoft Learning mslearn-dp100 \n",
    "\n",
    "Copyright (c) 2021 PyLadies Amsterdam, Alyona Galyeva"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create batch pipeline"
   ]
  },
  {
   "source": [
    "## Connect to your workspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "source": [
    "## Provision inference compute"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We'll need a compute context for the pipeline, so we'll use the following code to specify an Azure Machine Learning compute cluster (it will be created if it doesn't already exist).\n",
    "\n",
    "Important: Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"mlopsbootcamp\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS2_v2', max_nodes=2)\n",
    "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        inference_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "source": [
    "Note: Compute instances and clusters are based on standard Azure virtual machine images. For this exercise, the Standard_DS11_v2 image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Create a pipeline for batch inferencing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Now we're ready to define the pipeline we'll use for batch inferencing. Our pipeline will need Python code to perform the batch inferencing, so let's create a folder where we can keep all the files used by the pipeline:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'batch_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Model(workspace=Workspace.create(name='mlops', subscription_id='1e7eebf7-7dfc-4e94-9219-13ee1fc677f1', resource_group='mlops_bootcamp'), name=ridge, id=ridge:1, version=1, tags={}, properties={}), Model(workspace=Workspace.create(name='mlops', subscription_id='1e7eebf7-7dfc-4e94-9219-13ee1fc677f1', resource_group='mlops_bootcamp'), name=linear_regression, id=linear_regression:1, version=1, tags={}, properties={})] azureml-models/ridge/1/ridge.pkl\n"
     ]
    }
   ],
   "source": [
    "# let's check what models are registered in our workspace and get a path to our model of choice\n",
    "from azureml.core import Model\n",
    "model_list = Model.list(ws)\n",
    "#model_list\n",
    "#model_path = Model.get_model_path('linear_regression', _workspace=ws)\n",
    "model_path = Model.get_model_path('ridge', _workspace=ws)\n",
    "print(model_list, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('encoder',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [2, 3, 4])])),\n",
       "                ('regr_cv',\n",
       "                 RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                                    estimator=Ridge(fit_intercept=False),\n",
       "                                    n_iter=100, n_jobs=-1,\n",
       "                                    param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ffb6b85aac0>},\n",
       "                                    scoring='neg_mean_squared_error',\n",
       "                                    verbose=2))])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# let's load our model and take a look what's inside\n",
    "import joblib\n",
    "model = joblib.load(model_path)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch-data/155.csv\nbatch-data/141.csv\nbatch-data/97.csv\nbatch-data/83.csv\nbatch-data/68.csv\nbatch-data/6.csv\nbatch-data/54.csv\nbatch-data/40.csv\nbatch-data/41.csv\nbatch-data/7.csv\nbatch-data/55.csv\nbatch-data/69.csv\nbatch-data/82.csv\nbatch-data/168.csv\nbatch-data/96.csv\nbatch-data/140.csv\nbatch-data/154.csv\nbatch-data/142.csv\nbatch-data/156.csv\nbatch-data/80.csv\nbatch-data/94.csv\nbatch-data/43.csv\nbatch-data/57.csv\nbatch-data/5.csv\nbatch-data/56.csv\nbatch-data/4.csv\nbatch-data/42.csv\nbatch-data/95.csv\nbatch-data/81.csv\nbatch-data/157.csv\nbatch-data/143.csv\nbatch-data/85.csv\nbatch-data/91.csv\nbatch-data/147.csv\nbatch-data/153.csv\nbatch-data/46.csv\nbatch-data/52.csv\nbatch-data/1.csv\nbatch-data/53.csv\nbatch-data/47.csv\nbatch-data/152.csv\nbatch-data/146.csv\nbatch-data/90.csv\nbatch-data/84.csv\nbatch-data/92.csv\nbatch-data/86.csv\nbatch-data/150.csv\nbatch-data/144.csv\nbatch-data/51.csv\nbatch-data/3.csv\nbatch-data/45.csv\nbatch-data/79.csv\nbatch-data/78.csv\nbatch-data/44.csv\nbatch-data/50.csv\nbatch-data/2.csv\nbatch-data/145.csv\nbatch-data/151.csv\nbatch-data/87.csv\nbatch-data/93.csv\nbatch-data/136.csv\nbatch-data/122.csv\nbatch-data/37.csv\nbatch-data/23.csv\nbatch-data/22.csv\nbatch-data/36.csv\nbatch-data/123.csv\nbatch-data/137.csv\nbatch-data/121.csv\nbatch-data/135.csv\nbatch-data/109.csv\nbatch-data/20.csv\nbatch-data/34.csv\nbatch-data/35.csv\nbatch-data/21.csv\nbatch-data/108.csv\nbatch-data/134.csv\nbatch-data/120.csv\nbatch-data/118.csv\nbatch-data/124.csv\nbatch-data/130.csv\nbatch-data/25.csv\nbatch-data/31.csv\nbatch-data/19.csv\nbatch-data/18.csv\nbatch-data/30.csv\nbatch-data/24.csv\nbatch-data/131.csv\nbatch-data/125.csv\nbatch-data/119.csv\nbatch-data/133.csv\nbatch-data/127.csv\nbatch-data/32.csv\nbatch-data/26.csv\nbatch-data/27.csv\nbatch-data/33.csv\nbatch-data/126.csv\nbatch-data/132.csv\nbatch-data/117.csv\nbatch-data/103.csv\nbatch-data/16.csv\nbatch-data/17.csv\nbatch-data/102.csv\nbatch-data/116.csv\nbatch-data/100.csv\nbatch-data/114.csv\nbatch-data/128.csv\nbatch-data/29.csv\nbatch-data/15.csv\nbatch-data/14.csv\nbatch-data/28.csv\nbatch-data/129.csv\nbatch-data/115.csv\nbatch-data/101.csv\nbatch-data/139.csv\nbatch-data/105.csv\nbatch-data/111.csv\nbatch-data/10.csv\nbatch-data/38.csv\nbatch-data/39.csv\nbatch-data/11.csv\nbatch-data/110.csv\nbatch-data/104.csv\nbatch-data/138.csv\nbatch-data/112.csv\nbatch-data/106.csv\nbatch-data/13.csv\nbatch-data/12.csv\nbatch-data/107.csv\nbatch-data/113.csv\nbatch-data/160.csv\nbatch-data/148.csv\nbatch-data/49.csv\nbatch-data/75.csv\nbatch-data/61.csv\nbatch-data/60.csv\nbatch-data/74.csv\nbatch-data/48.csv\nbatch-data/149.csv\nbatch-data/161.csv\nbatch-data/163.csv\nbatch-data/89.csv\nbatch-data/62.csv\nbatch-data/76.csv\nbatch-data/77.csv\nbatch-data/63.csv\nbatch-data/88.csv\nbatch-data/162.csv\nbatch-data/98.csv\nbatch-data/166.csv\nbatch-data/67.csv\nbatch-data/73.csv\nbatch-data/9.csv\nbatch-data/8.csv\nbatch-data/72.csv\nbatch-data/66.csv\nbatch-data/99.csv\nbatch-data/167.csv\nbatch-data/159.csv\nbatch-data/165.csv\nbatch-data/70.csv\nbatch-data/64.csv\nbatch-data/58.csv\nbatch-data/59.csv\nbatch-data/65.csv\nbatch-data/71.csv\nbatch-data/164.csv\nbatch-data/158.csv\n"
     ]
    }
   ],
   "source": [
    "mini_batch = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(\"batch-data\"):\n",
    "    mini_batch += [os.path.join(dirpath, file) for file in filenames]\n",
    "for elem in mini_batch:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def run(mini_batch):\n",
    "    # This runs for each batch\n",
    "    resultList = []\n",
    "\n",
    "    # process each file in the batch\n",
    "    for f in mini_batch:\n",
    "        # Read comma-delimited data into an array\n",
    "        data = np.genfromtxt(f, delimiter=',')\n",
    "        # Reshape into a 2-dimensional array for model input\n",
    "        prediction = model.predict(data.reshape(1, -1))\n",
    "        # Append prediction to results\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['155.csv: 5659.044500303951',\n",
       " '141.csv: 6453.884022171924',\n",
       " '97.csv: 6928.96696728335',\n",
       " '83.csv: 8170.145488584927',\n",
       " '68.csv: 7784.777413082775',\n",
       " '6.csv: 5341.164708222638',\n",
       " '54.csv: 6458.972931004642',\n",
       " '40.csv: 9276.099392888733',\n",
       " '41.csv: 9407.473666585682',\n",
       " '7.csv: 5741.673875782065',\n",
       " '55.csv: 6951.1647928471375',\n",
       " '69.csv: 7563.930699813918',\n",
       " '82.csv: 8008.6322375151885',\n",
       " '168.csv: 5752.488346113794',\n",
       " '96.csv: 7378.310182120897',\n",
       " '140.csv: 6841.30735529549',\n",
       " '154.csv: 5570.239233745771',\n",
       " '142.csv: 6410.685029936254',\n",
       " '156.csv: 5978.729051596117',\n",
       " '80.csv: 6894.690090067934',\n",
       " '94.csv: 7972.5660248626355',\n",
       " '43.csv: 9174.429523783443',\n",
       " '57.csv: 8081.889057192055',\n",
       " '5.csv: 5103.042140965036',\n",
       " '56.csv: 7466.464606342966',\n",
       " '4.csv: 5154.152751208154',\n",
       " '42.csv: 9452.699673951993',\n",
       " '95.csv: 7833.375136665221',\n",
       " '81.csv: 7559.413494159684',\n",
       " '157.csv: 6055.433855551955',\n",
       " '143.csv: 6261.073602448914',\n",
       " '85.csv: 8688.790401584694',\n",
       " '91.csv: 8712.092725796098',\n",
       " '147.csv: 5229.389843090332',\n",
       " '153.csv: 5249.546335009299',\n",
       " '46.csv: 8329.550987707104',\n",
       " '52.csv: 6404.708059079809',\n",
       " '1.csv: 5759.551072825723',\n",
       " '53.csv: 6339.729491898965',\n",
       " '47.csv: 8187.577262645542',\n",
       " '152.csv: 5025.920100964523',\n",
       " '146.csv: 5490.177317930267',\n",
       " '90.csv: 9236.710791013036',\n",
       " '84.csv: 8470.653769317882',\n",
       " '92.csv: 8331.476606499156',\n",
       " '86.csv: 8813.040292198983',\n",
       " '150.csv: 5018.200548620694',\n",
       " '144.csv: 5978.735765487932',\n",
       " '51.csv: 6551.363349317877',\n",
       " '3.csv: 5249.984637572288',\n",
       " '45.csv: 8451.253602398452',\n",
       " '79.csv: 6372.632138930603',\n",
       " '78.csv: 5912.611176901726',\n",
       " '44.csv: 8779.163082511232',\n",
       " '50.csv: 6791.431988170252',\n",
       " '2.csv: 5488.556058504788',\n",
       " '145.csv: 5734.290159223572',\n",
       " '151.csv: 5108.4869882033445',\n",
       " '87.csv: 9006.526980574514',\n",
       " '93.csv: 8133.787296131713',\n",
       " '136.csv: 7181.863002967617',\n",
       " '122.csv: 6576.219846118713',\n",
       " '37.csv: 8757.7780915016',\n",
       " '23.csv: 7577.368181306869',\n",
       " '22.csv: 7716.843579647913',\n",
       " '36.csv: 8604.689830662903',\n",
       " '123.csv: 6322.681835178355',\n",
       " '137.csv: 7235.469335908549',\n",
       " '121.csv: 6870.019195815446',\n",
       " '135.csv: 7115.8768536543885',\n",
       " '109.csv: 8830.192150433815',\n",
       " '20.csv: 8161.376402292704',\n",
       " '34.csv: 8089.056798072783',\n",
       " '35.csv: 8380.222392948172',\n",
       " '21.csv: 7896.412083530664',\n",
       " '108.csv: 8641.637511105326',\n",
       " '134.csv: 7373.939850816623',\n",
       " '120.csv: 7177.643647780289',\n",
       " '118.csv: 7830.2068929476645',\n",
       " '124.csv: 6219.026663047825',\n",
       " '130.csv: 6734.383430396991',\n",
       " '25.csv: 6583.010728679439',\n",
       " '31.csv: 6346.834945503813',\n",
       " '19.csv: 8575.542282165734',\n",
       " '18.csv: 8842.313912870603',\n",
       " '30.csv: 5948.700881186867',\n",
       " '24.csv: 7023.254535411266',\n",
       " '131.csv: 6918.853334353735',\n",
       " '125.csv: 6111.005604476322',\n",
       " '119.csv: 7631.983537849677',\n",
       " '133.csv: 7259.437555789551',\n",
       " '127.csv: 6304.877220253387',\n",
       " '32.csv: 6885.832477511649',\n",
       " '26.csv: 6243.104119974707',\n",
       " '27.csv: 6011.25279686941',\n",
       " '33.csv: 7636.411741226728',\n",
       " '126.csv: 6213.591798967695',\n",
       " '132.csv: 7211.762744778445',\n",
       " '117.csv: 8037.945031601694',\n",
       " '103.csv: 6783.997579792542',\n",
       " '16.csv: 8626.759940822483',\n",
       " '17.csv: 8793.150340496893',\n",
       " '102.csv: 6294.679237523753',\n",
       " '116.csv: 8324.094168630352',\n",
       " '100.csv: 6114.46594826647',\n",
       " '114.csv: 8824.45530118716',\n",
       " '128.csv: 6135.484918793536',\n",
       " '29.csv: 5791.683644705025',\n",
       " '15.csv: 8354.07896480299',\n",
       " '14.csv: 8166.280360646873',\n",
       " '28.csv: 5844.894363938167',\n",
       " '129.csv: 6334.971308904334',\n",
       " '115.csv: 8482.8831470538',\n",
       " '101.csv: 6156.851918280159',\n",
       " '139.csv: 6870.203649854304',\n",
       " '105.csv: 7730.472261063816',\n",
       " '111.csv: 8852.76208449761',\n",
       " '10.csv: 7321.9885114057015',\n",
       " '38.csv: 8915.353383332813',\n",
       " '39.csv: 9082.816302817775',\n",
       " '11.csv: 7610.574988981969',\n",
       " '110.csv: 8930.277850634951',\n",
       " '104.csv: 7328.934520409204',\n",
       " '138.csv: 7205.355707855448',\n",
       " '112.csv: 8895.917960008948',\n",
       " '106.csv: 7639.333131056097',\n",
       " '13.csv: 8092.792345338858',\n",
       " '12.csv: 7897.803903194272',\n",
       " '107.csv: 8248.74423909715',\n",
       " '113.csv: 8934.871415909965',\n",
       " '160.csv: 6222.506954506813',\n",
       " '148.csv: 5058.2253825553125',\n",
       " '49.csv: 7209.341765969768',\n",
       " '75.csv: 5885.03451436103',\n",
       " '61.csv: 9053.11742721277',\n",
       " '60.csv: 9036.76916251771',\n",
       " '74.csv: 6103.697262448995',\n",
       " '48.csv: 7623.530268031442',\n",
       " '149.csv: 4993.827439735762',\n",
       " '161.csv: 6130.159175885394',\n",
       " '163.csv: 6017.955865501737',\n",
       " '89.csv: 9303.231269358797',\n",
       " '62.csv: 9205.039753427833',\n",
       " '76.csv: 5759.012462864319',\n",
       " '77.csv: 5751.774616826851',\n",
       " '63.csv: 8814.356037618782',\n",
       " '88.csv: 9139.020372244682',\n",
       " '162.csv: 6295.222587989008',\n",
       " '98.csv: 6468.2415582387475',\n",
       " '166.csv: 6178.11835320134',\n",
       " '67.csv: 7861.701502339874',\n",
       " '73.csv: 6467.909349626378',\n",
       " '9.csv: 6847.609751490176',\n",
       " '8.csv: 6228.957667993259',\n",
       " '72.csv: 6826.17084169945',\n",
       " '66.csv: 8886.776776727776',\n",
       " '99.csv: 6294.491054199441',\n",
       " '167.csv: 5992.373524032055',\n",
       " '159.csv: 6129.017133051515',\n",
       " '165.csv: 6054.229854936802',\n",
       " '70.csv: 7522.232579654474',\n",
       " '64.csv: 9057.023309980306',\n",
       " '58.csv: 8406.413066123023',\n",
       " '59.csv: 8699.472789901554',\n",
       " '65.csv: 9143.983000829867',\n",
       " '71.csv: 7334.331558201455',\n",
       " '164.csv: 6177.239843193111',\n",
       " '158.csv: 6152.458402659458']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "result = run(mini_batch)\n",
    "result"
   ]
  },
  {
   "source": [
    "Now we'll create a Python script to do the actual work, and save it in the pipeline folder:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting batch_pipeline/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/score.py\n",
    "# windows users\n",
    "# %%writefile $experiment_folder\\score.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from azureml.core import Model\n",
    "import joblib\n",
    "\n",
    "def init():\n",
    "    # Runs when the pipeline step is initialized\n",
    "    global model\n",
    "\n",
    "    # load the model\n",
    "    #model_path = Model.get_model_path('linear_regression')\n",
    "    model_path = Model.get_model_path('ridge')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(mini_batch):\n",
    "    # This runs for each batch\n",
    "    resultList = []\n",
    "\n",
    "    # process each file in the batch\n",
    "    for f in mini_batch:\n",
    "        # Read comma-delimited data into an array\n",
    "        data = np.genfromtxt(f, delimiter=',')\n",
    "        # Reshape into a 2-dimensional array for model input\n",
    "        prediction = model.predict(data.reshape(1, -1))\n",
    "        # Append prediction to results\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\n",
    "    return resultList"
   ]
  },
  {
   "source": [
    "The pipeline will need an environment in which to run, so we'll create a Conda specification that includes the packages that the code uses."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting batch_pipeline/batch_environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_environment.yml\n",
    "# windows users\n",
    "# %%writefile $experiment_folder\\batch_environment.yml\n",
    "name: batch_environment\n",
    "dependencies:\n",
    "- python=3.8\n",
    "- numpy\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- pip:\n",
    "  - azureml-core"
   ]
  },
  {
   "source": [
    "Next we'll define a run context that includes the Conda environment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Create an Environment for the experiment\n",
    "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_environment.yml\")\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "print('Configuration ready.')"
   ]
  },
  {
   "source": [
    "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a ParallelRunStep, which enables the batch data to be processed in parallel and the results collated in a single output file named parallel_run_step.txt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Steps defined\n",
      "/Users/leticialunatlatelpa/opt/anaconda3/envs/mlops_train/lib/python3.8/site-packages/azureml/pipeline/core/_parallel_run_step_base.py:591: UserWarning: \n",
      "ParallelRunStep requires azureml-dataset-runtime[fuse] for file dataset.\n",
      "Please add relevant package in CondaDependencies.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "# # Get the batch dataset for input\n",
    "batch_data_set = ws.datasets['batch-data']\n",
    "\n",
    "# Set the output location\n",
    "default_ds = ws.get_default_datastore()\n",
    "output_dir = OutputFileDatasetConfig(name='inferences')\n",
    "\n",
    "# Define the parallel run step step configuration\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=experiment_folder,\n",
    "    entry_script=\"score.py\",\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=inference_cluster,\n",
    "    node_count=2)\n",
    "\n",
    "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# Create the parallel run step\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name=parallel_step_name,\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('batch_data')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print('Steps defined')"
   ]
  },
  {
   "source": [
    "Now it's time to put the step into a pipeline, and run it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d.txt\n",
      "===============================================================================================================\n",
      "[2021-07-18T17:48:09.921845] Entering job release\n",
      "[2021-07-18T17:48:10.985819] Starting job release\n",
      "[2021-07-18T17:48:10.987345] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 372\n",
      "[2021-07-18T17:48:10.987957] job release stage : upload_datastore starting...\n",
      "[2021-07-18T17:48:10.988574] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-07-18T17:48:10.992106] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-07-18T17:48:10.992237] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-07-18T17:48:10.994920] Entering context manager injector.\n",
      "[2021-07-18T17:48:10.995202] job release stage : execute_job_release starting...\n",
      "[2021-07-18T17:48:11.008535] job release stage : upload_datastore completed...\n",
      "[2021-07-18T17:48:11.119586] job release stage : send_run_telemetry starting...\n",
      "[2021-07-18T17:48:11.132633] get vm size and vm region successfully.\n",
      "[2021-07-18T17:48:11.146263] job release stage : execute_job_release completed...\n",
      "[2021-07-18T17:48:11.164307] get compute meta data successfully.\n",
      "[2021-07-18T17:48:11.370866] post artifact meta request successfully.\n",
      "[2021-07-18T17:48:11.431463] upload compute record artifact successfully.\n",
      "[2021-07-18T17:48:11.431703] job release stage : send_run_telemetry completed...\n",
      "[2021-07-18T17:48:11.432330] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-07-18T17:48:11.432480] Running Sidecar release cmd...\n",
      "[2021-07-18T17:48:11.461434] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/16a5b924-1fdf-4229-8168-47e70697cf21/wd/azureml/16a5b924-1fdf-4229-8168-47e70697cf21\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/16a5b924-1fdf-4229-8168-47e70697cf21/wd/batch_data_7d1b86d0-fc2b-4d23-a7d8-a46d268d9cb0.\n",
      "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/16a5b924-1fdf-4229-8168-47e70697cf21/wd/batch_data_7d1b86d0-fc2b-4d23-a7d8-a46d268d9cb0: Invalid argument\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/16a5b924-1fdf-4229-8168-47e70697cf21/wd/batch_data_7d1b86d0-fc2b-4d23-a7d8-a46d268d9cb0.\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/16a5b924-1fdf-4229-8168-47e70697cf21/wd/inferences_workspaceblobstore.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/16a5b924-1fdf-4229-8168-47e70697cf21/wd/inferences_workspaceblobstore.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-07-18T17:48:11.519153] Removing absolute paths from host...\n",
      "[2021-07-18T17:48:11.519451] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-07-18T17:48:11.907191] Ran Sidecar release cmd.\n",
      "[2021-07-18T17:48:11.907286] Job release is complete\n",
      "\n",
      "StepRun(batchscoring-202107181937) Execution Summary\n",
      "=====================================================\n",
      "StepRun( batchscoring-202107181937 ) Status: Finished\n",
      "{'runId': '16a5b924-1fdf-4229-8168-47e70697cf21', 'target': 'mlopsbootcamp', 'status': 'Completed', 'startTimeUtc': '2021-07-18T17:45:14.004209Z', 'endTimeUtc': '2021-07-18T17:48:25.476211Z', 'properties': {'ContentSnapshotId': 'c9718b22-d4a3-40f6-968c-251bb65e041c', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'c4408db3-5b14-4a00-9698-bade5d806813', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '218ddfd8', 'azureml.pipelinerunid': 'a4cc758f-f2cf-4551-a20b-0e01cbc2ecd7', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.RuntimeType': '', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': '7d1b86d0-fc2b-4d23-a7d8-a46d268d9cb0'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'batch_data', 'mechanism': 'Mount'}}, {'dataset': {'id': 'c109802c-b02c-4ad4-a277-0ba0a0b4a8a7'}, 'consumptionDetails': {'type': 'Reference'}}], 'outputDatasets': [{'identifier': {'savedId': 'c109802c-b02c-4ad4-a277-0ba0a0b4a8a7'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'inferences'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'dataset/16a5b924-1fdf-4229-8168-47e70697cf21/inferences/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"c109802c-b02c-4ad4-a277-0ba0a0b4a8a7\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='mlops', subscription_id='1e7eebf7-7dfc-4e94-9219-13ee1fc677f1', resource_group='mlops_bootcamp')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.32.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'batch_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'mlopsbootcamp', 'dataReferences': {}, 'data': {'batch_data': {'dataLocation': {'dataset': {'id': '7d1b86d0-fc2b-4d23-a7d8-a46d268d9cb0', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'batch_data', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {'inferences': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': '/tmp/8f18aaf5-07a5-4264-b5dd-7c40bbc46f6d/', 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2021-07-17T16:49:44Z_1ac00ccf', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.8', 'numpy', 'pandas', 'scikit-learn', {'pip': ['azureml-core']}], 'name': 'azureml_0e994e8f6dddd5a9062958e2f1cf1205'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': None, 'slaTier': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/azureml-logs/55_azureml-execution-tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d.txt?sv=2019-02-02&sr=b&sig=biOeZJqTMeyRh3c5LN3x4w40ggJRrQzSMEWV4606XBs%3D&st=2021-07-18T17%3A38%3A18Z&se=2021-07-19T01%3A48%3A18Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/azureml-logs/55_azureml-execution-tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d.txt?sv=2019-02-02&sr=b&sig=9MFc8fUGtQwm0ChAaMJn3CRA%2FdRTjA%2FZTx4Vbj7zoF4%3D&st=2021-07-18T17%3A38%3A18Z&se=2021-07-19T01%3A48%3A18Z&sp=r', 'azureml-logs/65_job_prep-tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/azureml-logs/65_job_prep-tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d.txt?sv=2019-02-02&sr=b&sig=9DJcL6lsMfKouzAAszSURQAQh9B8VPLnSsMnx6xoyrg%3D&st=2021-07-18T17%3A38%3A18Z&se=2021-07-19T01%3A48%3A18Z&sp=r', 'azureml-logs/65_job_prep-tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/azureml-logs/65_job_prep-tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d.txt?sv=2019-02-02&sr=b&sig=aJJ5E3%2FLEk8uD1QdQwBbchBTSkoj%2F17weMtKlGrC7XE%3D&st=2021-07-18T17%3A38%3A18Z&se=2021-07-19T01%3A48%3A18Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=rhHUwViC41l82yrbA2%2B2yzh5EkQhUI3VTjm1T6AAZdU%3D&st=2021-07-18T17%3A38%3A18Z&se=2021-07-19T01%3A48%3A18Z&sp=r', 'azureml-logs/75_job_post-tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/azureml-logs/75_job_post-tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d.txt?sv=2019-02-02&sr=b&sig=YsxBrprntx0XveitoZUkNiDixZaAgrGBD2JP3sNuQiM%3D&st=2021-07-18T17%3A38%3A18Z&se=2021-07-19T01%3A48%3A18Z&sp=r', 'azureml-logs/75_job_post-tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/azureml-logs/75_job_post-tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d.txt?sv=2019-02-02&sr=b&sig=Hn0J1aViEg6nofXE2bRcLstAKj97Jcv15oOD4vlebRw%3D&st=2021-07-18T17%3A38%3A18Z&se=2021-07-19T01%3A48%3A18Z&sp=r', 'azureml-logs/process_info.json': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=WZQKUqfAZsHq58Q4is0cLfe8hjIUy1cxguKGIUF%2BtvU%3D&st=2021-07-18T17%3A38%3A18Z&se=2021-07-19T01%3A48%3A18Z&sp=r', 'azureml-logs/process_status.json': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=R4udS3WHaF533sGOgYuTIDepmt0P%2FroJlpmsxICh%2BAU%3D&st=2021-07-18T17%3A38%3A18Z&se=2021-07-19T01%3A48%3A18Z&sp=r', 'logs/azureml/103_azureml.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/103_azureml.log?sv=2019-02-02&sr=b&sig=gGhQSVvnspl3xT3LatKOpDwqpKSZfJqUMMs15DhRCwg%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/150_azureml.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/150_azureml.log?sv=2019-02-02&sr=b&sig=IBEe2w69LYW4j97gN3D%2FcMuvi5d012UiuB6GXeXuNb0%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/88_azureml.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/88_azureml.log?sv=2019-02-02&sr=b&sig=8a%2BvEqfHksiB0HEJNzlZAXaQGremiXDob00E6et6On8%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=4P9rQpgwe7HH%2FX3Zviq83iIwQmx5zV28Qao4ZO1TroE%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=3%2BA3pcK8IlnAWLWzCLaFpx2UA4llSLamHJoLvqObN3s%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=WWk8pMMI4BRFy6CCysPbuRlY25px8ld2hKi52Qpl4mQ%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=z3Hxi%2F0v99liz8VKDiv4ojT2srv7YrTV9kGVQ%2BF0KvU%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=fk1OCEd2St7foED7evYaybp43hsSgxcJZ5p52dWKUmQ%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d/all.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/sidecar/tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d/all.log?sv=2019-02-02&sr=b&sig=DYI8BJ7EaGDsNWDHWpUatjnfWoNOGarYFBQ9IiW2PVg%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d/task.enter_contexts.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/sidecar/tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=QPgb1hc%2Fu3x3qwzvo%2BAyfp8ieIaGuHfSc7z9fOloHh0%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d/task.exit_contexts.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/sidecar/tvmps_41bddfece57173a5c74e963e10b59ffcfe3711de3ec847ca1f92b9fd5c3003a2_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=eTSmNuVgppH0yLiFLZH3agRd4YICeUHso7ymMxQYzm0%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d/all.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/sidecar/tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d/all.log?sv=2019-02-02&sr=b&sig=jw1u2GByEIrMkeftTFDCXi26FCEWpil4QNjHqbJQsxg%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d/task.enter_contexts.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/sidecar/tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=Ff5abgr4FRAJdeQwDMi1V7Vh0%2BuNCRrAG9yoGdNLIsU%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d/task.exit_contexts.log': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/sidecar/tvmps_71d401317409abb09b527b14584b01293d2322f7491880346eff45dc0be5a63c_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=SUK1YnxUVC5XAA8cdyKFh2dJzxpFyIqmn%2FuPZkIA9m0%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=baR5xPsADJ7ZCbJp%2B2bZ%2BJHn2E2oTLfx4cbYPS8Kc8A%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.16a5b924-1fdf-4229-8168-47e70697cf21/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=q5tcusae7lH2g1lfoe%2FMgu51cHOr49XqoACp462E%2Feg%3D&st=2021-07-18T17%3A38%3A15Z&se=2021-07-19T01%3A48%3A15Z&sp=r'}, 'submittedBy': 'Leticia Luna Tlatelpa'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'a4cc758f-f2cf-4551-a20b-0e01cbc2ecd7', 'status': 'Completed', 'startTimeUtc': '2021-07-18T17:38:23.942374Z', 'endTimeUtc': '2021-07-18T17:48:28.81823Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.a4cc758f-f2cf-4551-a20b-0e01cbc2ecd7/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=cRKwiBCvBh0n%2BVlp%2BpaSAtsilfO0Q42dctZ0dOZdcnE%3D&st=2021-07-18T17%3A30%3A10Z&se=2021-07-19T01%3A40%3A10Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.a4cc758f-f2cf-4551-a20b-0e01cbc2ecd7/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=DQhEWsV6AL53ET0quOP8gPrezUpDg%2FCXBJWwkhf40hY%3D&st=2021-07-18T17%3A30%3A10Z&se=2021-07-19T01%3A40%3A10Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsstorage271b94365505.blob.core.windows.net/azureml/ExperimentRun/dcid.a4cc758f-f2cf-4551-a20b-0e01cbc2ecd7/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=XddxLhhgNJwBas%2FaufgzkZ9mHsHBpipEJgC2%2F8%2FeSmI%3D&st=2021-07-18T17%3A30%3A10Z&se=2021-07-19T01%3A40%3A10Z&sp=r'}, 'submittedBy': 'Leticia Luna Tlatelpa'}\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "\n",
    "# Run the pipeline as an experiment\n",
    "pipeline_run = Experiment(ws, 'nyc-energy-demand-batch').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "source": [
    "When the pipeline has finished running, the resulting predictions will have been saved in the outputs of the experiment associated with the first (and only) step in the pipeline. You can retrieve it as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       File   Prediction\n",
       "0     1.csv  5759.551073\n",
       "1    10.csv  7321.988511\n",
       "2   100.csv  6114.465948\n",
       "3   101.csv  6156.851918\n",
       "4   102.csv  6294.679238\n",
       "5   103.csv  6783.997580\n",
       "6   104.csv  7328.934520\n",
       "7   105.csv  7730.472261\n",
       "8   106.csv  7639.333131\n",
       "9   107.csv  8248.744239\n",
       "10  108.csv  8641.637511\n",
       "11  109.csv  8830.192150\n",
       "12   11.csv  7610.574989\n",
       "13  110.csv  8930.277851\n",
       "14  111.csv  8852.762084\n",
       "15  112.csv  8895.917960\n",
       "16  113.csv  8934.871416\n",
       "17  114.csv  8824.455301\n",
       "18  115.csv  8482.883147\n",
       "19  116.csv  8324.094169"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.csv</td>\n      <td>5759.551073</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.csv</td>\n      <td>7321.988511</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100.csv</td>\n      <td>6114.465948</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>101.csv</td>\n      <td>6156.851918</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>102.csv</td>\n      <td>6294.679238</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>103.csv</td>\n      <td>6783.997580</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>104.csv</td>\n      <td>7328.934520</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>105.csv</td>\n      <td>7730.472261</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>106.csv</td>\n      <td>7639.333131</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>107.csv</td>\n      <td>8248.744239</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>108.csv</td>\n      <td>8641.637511</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>109.csv</td>\n      <td>8830.192150</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11.csv</td>\n      <td>7610.574989</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>110.csv</td>\n      <td>8930.277851</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>111.csv</td>\n      <td>8852.762084</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>112.csv</td>\n      <td>8895.917960</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>113.csv</td>\n      <td>8934.871416</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>114.csv</td>\n      <td>8824.455301</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>115.csv</td>\n      <td>8482.883147</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>116.csv</td>\n      <td>8324.094169</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Remove the local results folder if left over from a previous run\n",
    "shutil.rmtree('batch-results', ignore_errors=True)\n",
    "\n",
    "# Get the run for the first step and download its output\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='batch-results')\n",
    "\n",
    "# Traverse the folder hierarchy and find the results file\n",
    "for root, dirs, files in os.walk('batch-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# cleanup output format\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "# Display the first 20 results\n",
    "df.head(20)"
   ]
  },
  {
   "source": [
    "## Publish the Pipeline and use its REST Interface"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Now that you have a working pipeline for batch inferencing, you can publish it and use a REST endpoint to run it from an application."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(Name: Ridge_regression_batch_prediction_pipeline,\n",
       "Id: 314c8917-07d1-4dde-bd08-01f664f454ca,\n",
       "Status: Active,\n",
       "Endpoint: https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/1e7eebf7-7dfc-4e94-9219-13ee1fc677f1/resourceGroups/mlops_bootcamp/providers/Microsoft.MachineLearningServices/workspaces/mlops/PipelineRuns/PipelineSubmit/314c8917-07d1-4dde-bd08-01f664f454ca)"
      ],
      "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Ridge_regression_batch_prediction_pipeline</td><td><a href=\"https://ml.azure.com/pipelines/314c8917-07d1-4dde-bd08-01f664f454ca?wsid=/subscriptions/1e7eebf7-7dfc-4e94-9219-13ee1fc677f1/resourcegroups/mlops_bootcamp/workspaces/mlops\" target=\"_blank\" rel=\"noopener\">314c8917-07d1-4dde-bd08-01f664f454ca</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/1e7eebf7-7dfc-4e94-9219-13ee1fc677f1/resourceGroups/mlops_bootcamp/providers/Microsoft.MachineLearningServices/workspaces/mlops/PipelineRuns/PipelineSubmit/314c8917-07d1-4dde-bd08-01f664f454ca\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#published_pipeline = pipeline_run.publish_pipeline(name='Linear_regression_batch_prediction_pipeline',\n",
    "#                                                   description='Batch scoring using linear regression model',\n",
    "#                                                   version='1.0')\n",
    "\n",
    "published_pipeline = pipeline_run.publish_pipeline(name='Ridge_regression_batch_prediction_pipeline',\n",
    "                                                   description='Batch scoring using ridge regression model',\n",
    "                                                   version='1.0')\n",
    "published_pipeline"
   ]
  },
  {
   "source": [
    "Note that the published pipeline has an endpoint, which you can see in the Azure portal. You can also find it as a property of the published pipeline object:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/1e7eebf7-7dfc-4e94-9219-13ee1fc677f1/resourceGroups/mlops_bootcamp/providers/Microsoft.MachineLearningServices/workspaces/mlops/PipelineRuns/PipelineSubmit/314c8917-07d1-4dde-bd08-01f664f454ca\n"
     ]
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. To test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:\n",
    "\n",
    "Note: A real application would require a service principal with which to be authenticated."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Authentication header ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print('Authentication header ready.')"
   ]
  },
  {
   "source": [
    "Once published, you can use this endpoint to initiate a batch inferencing job, as shown in the following example code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'e47fe786-42be-40fc-bf4d-ef7b25099200'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": \"nyc-energy-demand-batch\"})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "source": [
    "You can also schedule the published pipeline to have it run automatically, as shown in the following example code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
    "\n",
    "#weekly = ScheduleRecurrence(frequency='Week', interval=1)\n",
    "daily = ScheduleRecurrence(frequency='Day', interval=1)\n",
    "daily = \n",
    "pipeline_schedule = Schedule.create(ws, name='Weekly Predictions',\n",
    "                                        description='batch inferencing',\n",
    "                                        pipeline_id=published_pipeline.id,\n",
    "                                        experiment_name='Batch_Prediction',\n",
    "                                        recurrence=daily)"
   ]
  },
  {
   "source": [
    "IMPORTANT: Remove inference cluster if you do not plan to work on exercises immediately!!!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mlops_train': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "a2bc39ff78dd4a73106c234fbd4de5427fb8e6406827c32a9355c92b962a3927"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}